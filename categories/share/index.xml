<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Share on wrfly&#39;s blog</title>
    <link>https://wrfly.kfd.me/categories/share/</link>
    <description>Recent content in Share on wrfly&#39;s blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <lastBuildDate>Sat, 20 Jan 2018 14:52:01 +0800</lastBuildDate>
    
	<atom:link href="https://wrfly.kfd.me/categories/share/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Token-Bucket-II</title>
      <link>https://wrfly.kfd.me/posts/token-bucket-ii/</link>
      <pubDate>Sat, 20 Jan 2018 14:52:01 +0800</pubDate>
      
      <guid>https://wrfly.kfd.me/posts/token-bucket-ii/</guid>
      <description>昨天公司年会上中了一部iPhoneX，感觉用尽了积攒了二十多年的运气。
 上回说到用ticker的方式后台fill令牌桶的效率是最高的，然后鄙人就很奇怪，所以就又刨根问底测试了一下，发现在单核的情况下（用docker的方式绑定CPU到容器），如果有大于100个协程在run的话，性能的确会受影响。
代码: https://gist.github.com/wrfly/3f2b23b20d53fbe5f9fee8e8f89fe861
CPU: Intel(R) Core(TM) i7-7600U CPU @ 2.80GHz
多核情况下的性能对比: ➜ ratelimit ./ratelimit 2018/01/20 15:10:28 start testing... 2018/01/20 15:10:28 5s test 2018/01/20 15:10:33 juju[lock]: 5.000108905 2018/01/20 15:10:33 take: 6000 2018/01/20 15:10:33 drop: 35740301 2018/01/20 15:10:33 2018/01/20 15:10:38 bsm[atomic]: 5.000146318 2018/01/20 15:10:38 take: 6000 2018/01/20 15:10:38 drop: 57423059 2018/01/20 15:10:38 2018/01/20 15:10:43 wrfly: 5.000100057 2018/01/20 15:10:43 take: 5000 2018/01/20 15:10:43 drop: 116287439 2018/01/20 15:10:43 2018/01/20 15:10:48 tb: 5.</description>
    </item>
    
    <item>
      <title>Token-Bucket</title>
      <link>https://wrfly.kfd.me/posts/token-bucket/</link>
      <pubDate>Sun, 14 Jan 2018 01:07:51 +0800</pubDate>
      
      <guid>https://wrfly.kfd.me/posts/token-bucket/</guid>
      <description>上周解决的bug（其实并不能算是bug，是因为量太大导致的OOM）用到了令牌桶，简单在此记录一下。
关于令牌桶，最早接触的时候还是实习的时候用到的tc，这货限流就是用的令牌桶，简单地说，就是有一个桶，这个桶中有一些令牌，每进来一个包，就拿走一个令牌，当一定时间内（比如说，一秒）令牌被拿完了，那接下来的包就被丢弃了，因为他们没有拿到令牌；等到下一个时间周期，桶中再次被填满令牌，然后包来了再拿。
更详尽的参考：限流:漏桶算法和令牌桶算法  其中也有wikipedia的链接。
关于实现，github上搜到的golang的实现有这几个：
 https://github.com/bsm/ratelimit https://github.com/juju/ratelimit https://github.com/tsenart/tb  (P.S 还有我的hhh token bucket)
大体思路有这几个：
 使用lock+对比时间 使用原子操作+对比时间 使用原子操作+后台填桶（tikcer）  令牌桶其实很简单，就看怎样实现性能最好。
使用lock去拿token（看桶里还有没有token），然后再对比一下上次填桶的时间和取token的时间，就可以判断这个token能不能取到，这种实现的弊处在于lock的引入在数据量很大的情况下带来了不必要的lock和unlock，引起性能的下降。
所以就引出了第二种方案，使用原子操作来取代lock，性能有很大的提升。对比测试在下文中有代码。
可能会有人问，为什么要用对比时间的方式呢，后台用一个ticker定时填满不就行了。这也是我一开始想到的，但实际操作中却出现了问题，不知道是我姿势不对还是什么，测出的效果很差，怀疑是ticker没有定时执行，CPU没能调度到它上，没有来得及重置bucket。
然后就到了最后一种方式，后台填桶。这是最直白的，开一个goroutine每隔一段时间更新bucket中的token数量。但是，理论上在高并发的情况下，CPU繁忙，go出去的ticker容易失效（goroutine没能得到CPU资源），但实际情况却。。。大大超出我的想想，这种方法竟然是效率最高的！！！
对比测试：token-bucket-test.go
2018/01/13 18:05:17 5s test 2018/01/13 18:05:22 bsm: 5.000064716 2018/01/13 18:05:22 take: 6000 2018/01/13 18:05:22 drop: 54533531 2018/01/13 18:05:22 2018/01/13 18:05:28 wrfly: 5.000066249 2018/01/13 18:05:28 take: 4977 2018/01/13 18:05:28 drop: 57039560 2018/01/13 18:05:28 2018/01/13 18:05:34 tb: 5.000073633 2018/01/13 18:05:34 take: 6000 2018/01/13 18:05:34 drop: 113551687 2018/01/13 18:05:34 2018/01/13 18:05:35 range test: 100000000 2018/01/13 18:05:35 dry run: 0.</description>
    </item>
    
    <item>
      <title>Logrotate-Problem</title>
      <link>https://wrfly.kfd.me/posts/logrotate-problem/</link>
      <pubDate>Mon, 08 Jan 2018 20:59:37 +0800</pubDate>
      
      <guid>https://wrfly.kfd.me/posts/logrotate-problem/</guid>
      <description>今天遇到一个logrotate的问题。
现象是配置不生效（其实也不是完全不生效，只是每小时的滚转策略变成一天了）。
配置文件：
# see &amp;#34;man logrotate&amp;#34; for details # rotate log files weekly weekly # keep 4 weeks worth of backlogs rotate 4 # create new (empty) log files after rotating old ones create # use date as a suffix of the rotated file dateext # uncomment this if you want your log files compressed #compress # packages drop log rotation information into this directory include /etc/logrotate.d$ ls -l /etc/cron.</description>
    </item>
    
    <item>
      <title>Share-Memory-by-Communicating</title>
      <link>https://wrfly.kfd.me/posts/share-memory-by-communicating/</link>
      <pubDate>Sat, 06 Jan 2018 20:39:56 +0800</pubDate>
      
      <guid>https://wrfly.kfd.me/posts/share-memory-by-communicating/</guid>
      <description>Origin: https://blog.golang.org/share-memory-by-communicating
传统的多线程编程（比如Java，C++，Python等）需要码农通过在线程间共享内存的方式通信。一般来讲，共享的数据结构用锁来保护，线程想获取数据的时候必须先拿到锁。在某些情况下，用线程安全的数据结构能使其变得更加容易，比如Python的Queue。
Go的并发原语 - goroutine和channel - 提供了另一种优雅的方式去写并发软件。（这些概念有一个有趣的历史，起源于C. A. R. Hoare的 Communicating Sequential Processes）Go鼓励用channel的方式在goroutine之间传递引用数据，而不是声明一把锁去协调对共享数据的访问。这样的操作保证了在同一时刻只有一个goroutine拥有对数据的访问权。这个概念在高效Go编程（go程序员的必读文档）中有总结。
 不要通过共享的方式去沟通，通过沟通的方式共享内存。
 考虑这样一个程序，它轮旬一堆的URL。在传统的多线程编程中，你或许用以下的数据结构：
type Resource struct { url string polling bool lastPolled int64 } type Resources struct { data []*Resource lock *sync.Mutex } 然后有一个Poller的函数（并发执行）看起来可能会这样：
func Poller(res *Resources) { for { // get the least recently-polled Resource  // and mark it as being polled  res.lock.Lock() var r *Resource for _, v := range res.data { if v.</description>
    </item>
    
  </channel>
</rss>