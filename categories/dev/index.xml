<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Dev on wrfly&#39;s blog</title>
    <link>https://wrfly.kfd.me/categories/dev/</link>
    <description>Recent content in Dev on wrfly&#39;s blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <lastBuildDate>Tue, 20 Feb 2018 20:05:06 +0800</lastBuildDate>
    
	<atom:link href="https://wrfly.kfd.me/categories/dev/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Discover-sync.Pool</title>
      <link>https://wrfly.kfd.me/posts/discover-sync.pool/</link>
      <pubDate>Tue, 20 Feb 2018 20:05:06 +0800</pubDate>
      
      <guid>https://wrfly.kfd.me/posts/discover-sync.pool/</guid>
      <description>其实很久之前就用到了这个东西，起因是collecter程序占用太多内存了，然后就用sync.Pool复用额外消耗的一次性内存，避免GC周期太长使内存来不及释放而导致的OOM。
https://golang.org/pkg/sync/#Pool
简单的说，就是在一个池子里放了一些“东西”，这些东西是某种特殊的类型，用的时候需要指定。
池子会随着你的取用而扩张，比如说，池子里面放了扳手（扳手池），现在有10个工人依次取用，当第一个人取的时候，“扳手池”发现没有扳手，ok，new一个出来; 当第一个工人用完了的时候，把扳手放回扳手池，然后第二个人取的时候，扳手池就直接返回那个扳手就可以了。嗯……如果第一个工人没有归还呢，那么扳手池就要重新new一个扳手了，也就是这种情况：10个工人同时取用扳手，那么扳手池就得new10个新的出来了。
一个测试：
https://gist.github.com/wrfly/7de7f1e0c87860aa2f92dc6ed64cb75b
Makefile：
.PHONY: build run test NAME := $(shell basename `pwd`) build: go build run: ./$(NAME) test: build run go tool pprof -lines $(NAME) mem.porf  上面那个gist中，有几个测试，在这种情况下：
wg.Add(alloc) for i := 0; i &amp;lt; alloc; i++ { go func(num int) { // justMake() 	// bufPoolGet() 	bufPoolGetAndPut(num) // bufPoolSleepAndGetAndPut(num) 	wg.Done() }(i) } 也就是拿了接着放回去的时候，结果如下：
➜ syncPool_mem_usage_test make run go build ./syncPool_mem_usage_test newmake: 4 reused: 9996 reused slice(maybe equal to newmake) len: 0 ➜ syncPool_mem_usage_test  也就是说，新分配了4个1e6长度的[]byte，其余的都是复用的。</description>
    </item>
    
    <item>
      <title>RWMutex-and-sync.Map</title>
      <link>https://wrfly.kfd.me/posts/rwmutex-and-sync.map/</link>
      <pubDate>Sat, 03 Feb 2018 20:34:48 +0800</pubDate>
      
      <guid>https://wrfly.kfd.me/posts/rwmutex-and-sync.map/</guid>
      <description>In the last post, I noted a problem of read-and-write in high-cocurrency situation and finally chose to use sync.Map. This post I will make a comparation between map with RWMutex and sync.Map.
Read-or-Write Test Code package main import ( &amp;#34;fmt&amp;#34; &amp;#34;sync&amp;#34; &amp;#34;time&amp;#34; ) type rwMap struct { data map[int]int m sync.RWMutex } var ( rwm = rwMap{data: make(map[int]int)} end = int(1e7) syncM sync.Map ) func main() { fmt.Println(&amp;#34;write test&amp;#34;) // rw map 	start := time.</description>
    </item>
    
    <item>
      <title>Read-and-Write-in-High-Concurrency</title>
      <link>https://wrfly.kfd.me/posts/read-and-write-in-high-concurrency/</link>
      <pubDate>Fri, 02 Feb 2018 19:17:28 +0800</pubDate>
      
      <guid>https://wrfly.kfd.me/posts/read-and-write-in-high-concurrency/</guid>
      <description>问题 今天遇到一个高并发读写的问题。
具体的场景是，有一个“策略”的集合，然后每秒有很多消息进来，每一条消息都要匹配有没有对应的策略，如果有的话就应用策略（更改消息的某个属性），没有的话就返回。
抽象来看，就是在N多读的同时，怎样去写数据。
一开始我的方法是策略存在数组里，消息来了就去遍历数组，如果匹配到了就返回对应的规则。这种方法最笨，因为每一条消息过来，我都要去循环遍历整个数组，如果数组很长的话（有很多规则），那么带来的无谓开销会很大，复杂度为O(n)。
而且还一个问题，如果在range数组的时候，数组发生了变化，那么就会读到错误的值，或者崩溃。
一种解决的方法是，在遍历之前，首先拷贝一份新的，遍历新的策略数组，而不是原有的全局变量。这种方法的问题在于，每次匹配规则的时候，都要进行一次拷贝，虽然简单，也能解决问题，但，太浪费资源，而且很丑。
最终的思路是，用哈希表的方式去匹配策略，从复杂度上来看是O(1)的操作，但问题在于并发读写哈希表。
复现 为了更容易的表示问题，用了大量的并发读写（实际情况没有下面那么频繁，写操作要比读操作少得多得多）：
package main import ( &amp;#34;fmt&amp;#34; &amp;#34;time&amp;#34; ) var biu map[int]int func read() { for i := 0; i &amp;lt; len(biu); i++ { if biu[i] != i { fmt.Printf(&amp;#34;%d != %d\n&amp;#34;, biu[i], i) panic(&amp;#34;!&amp;#34;) } } } func write() { for i := 0; i &amp;lt; time.Now().Second(); i++ { biu[i] = i } } func main() { biu = make(map[int]int) go func() { for { go write() time.</description>
    </item>
    
  </channel>
</rss>